{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "可以使用  \n",
    "```python\n",
    "Pipeline([('dataprocess',dataprocessor()),('testmodel', learner())])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Transformer:\n",
    ">需要繼承 \n",
    "> - sklearn.base.TransformerMixin \n",
    "> - sklearn.base.BaseEstimator \n",
    "\n",
    ">需實作:  \n",
    "> - fit(self, datax, datay=None, **params)\n",
    "> - transform(self, datax, datay=None, **params)\n",
    "\n",
    "Learner:\n",
    ">需要繼承 \n",
    "> - sklearn.base.BaseEstimator \n",
    "\n",
    ">需實作:  \n",
    "> - fit(self, datax, datay=None, **params)\n",
    "> - predict(self, datay)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "class dataprocessor(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.total = 0.\n",
    "    def fit(self, datax, datay=None, **params):\n",
    "        #print(\"dataprocessor: 1) fit\")\n",
    "        self.total = sum(datax)\n",
    "        return self\n",
    "    def transform(self, datax, datay=None, **params):\n",
    "        #print(\"dataprocessor: 2) after fit, call transform\")\n",
    "        return [i/self.total for i in datax]\n",
    "\n",
    "class learner(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.condiction = 0.\n",
    "        pass\n",
    "    def fit(self, datax, datay=None, **params):\n",
    "        #print(\"learner: 1) fit\")\n",
    "        self.condiction = sum(datax)/len(datax)\n",
    "        return self\n",
    "    def predict(self, datax):\n",
    "        predicted = datax > self.condiction\n",
    "        return [int(i) for i in predicted]\n",
    "\n",
    "ml_pipe = Pipeline([('dataprocess',dataprocessor()),('testmodel', learner())])    \n",
    "X=np.array([1,2,3])\n",
    "y=np.array([1,0,1])\n",
    "ml_pipe.fit(X,y)\n",
    "ml_pipe.predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "GridSearchCV的param_grid會每次init物件完會呼叫set_params代入參數, 再呼叫fit跟transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('dataprocess', dataprocessor(bias=2, method='ori')), ('testmodel', learner(alpha=0.01))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#1) init 2) set_params 2) fit\n",
    "class dataprocessor(TransformerMixin,BaseEstimator):\n",
    "    def __init__(self, bias=1, method='mean'):\n",
    "        self.options = {'method': method, 'bias':bias} \n",
    "        self.total = 0.\n",
    "    def fit(self, datax, datay=None, **params):\n",
    "        self.total = sum(datax)\n",
    "        return self\n",
    "    def transform(self, datax, datay=None, **params):\n",
    "        #print(\"dataprocessor: 2) after fit, call transform\")\n",
    "        if (self.options['method'] == 'mean'):\n",
    "            return [(i/self.total)+self.options['bias'] for i in datax]\n",
    "        else:\n",
    "            return [i for i in datax]      \n",
    "    def set_params(self,**params):\n",
    "        for p in params:\n",
    "            self.options[p] = params[p]\n",
    "    def get_params(self,deep=True):\n",
    "        return self.options\n",
    "                \n",
    "class learner(BaseEstimator):\n",
    "    def __init__(self, alpha=0.1):\n",
    "        self.options = {'alpha':alpha} \n",
    "        self.condiction = 0.\n",
    "        pass\n",
    "    def fit(self, datax, datay=None, **params):\n",
    "        #print(\"learner: 1) fit\")\n",
    "        self.condiction = sum(datax)/len(datax) + self.options['alpha']\n",
    "        return self\n",
    "    def predict(self, datax):\n",
    "        predicted = datax > self.condiction\n",
    "        return [int(i) for i in predicted]\n",
    "    def score(self, X, y=None):\n",
    "        return np.random.rand()\n",
    "    def set_params(self,**params):\n",
    "        for p in params:\n",
    "            self.options[p] = params[p]\n",
    "    def get_params(self,deep=True):\n",
    "        return self.options\n",
    "\n",
    "ml_pipe = Pipeline([('dataprocess',dataprocessor()),('testmodel', learner())])    \n",
    "\n",
    "X=np.array([1,2,3,4,5,6,7,8,9,10,11])\n",
    "y=np.array([1,0,1,1,1,1,1,1,1,1,1])\n",
    "\n",
    "param_grid = {\n",
    "    'dataprocess__bias': [1,2],\n",
    "    'dataprocess__method': ['mean', 'ori'],\n",
    "    'testmodel__alpha': [.001, 0.01],\n",
    "    }\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "# estimator need provide a score function\n",
    "gsearch = GridSearchCV(estimator=ml_pipe, param_grid=param_grid, cv=kf,iid=False, n_jobs=1)\n",
    "gsearch.fit(X, y)\n",
    "print(gsearch.best_estimator_)\n",
    "#print(gsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 實現支援GridSearch的類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'SVC__C': 1,\n",
       "  'SVC__kernel': 'linear',\n",
       "  'dataProcess__caterogy_pipe__caterogy_imputer_step__fill_value': 'AAA',\n",
       "  'dataProcess__num_pipe__num_imputer_step__strategy': 'median'},\n",
       " 0.9733333333333333)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class dataProcess:\n",
    "    def __init__(self,aaa=0):\n",
    "        self.options = {'aaa':aaa}\n",
    "        self.caterogy_imputer_step = ('caterogy_imputer_step', SimpleImputer(strategy='constant',fill_value='MISSING')) \n",
    "        self.caterogy_encoder_step = ('caterogy_encoder_step', OneHotEncoder(sparse=False,handle_unknown='ignore')) \n",
    "        self.num_imputer_step = ('num_imputer_step', SimpleImputer(strategy='median'))\n",
    "        self.num_scaler_step = ('num_scaler_step', StandardScaler())\n",
    "        self.something = {\n",
    "            'caterogy_pipe': Pipeline([self.caterogy_imputer_step, self.caterogy_encoder_step]),\n",
    "            'num_pipe': Pipeline([self.num_imputer_step, self.num_scaler_step])\n",
    "        }\n",
    "    def fit(self, datax, datay=None):\n",
    "        # X is pandas type\n",
    "        kinds = np.array([dt.kind for dt in datax.dtypes])\n",
    "        is_num = kinds != 'O'\n",
    "        numeric_column_name = datax.columns.values[is_num]\n",
    "        category_column_name = datax.columns.values[~is_num]\n",
    "        self.ct_transformer = [('caterogy_transformer',self.something['caterogy_pipe'], category_column_name),('num_transformer',self.something['num_pipe'],numeric_column_name)]\n",
    "        self.ct = ColumnTransformer(transformers=self.ct_transformer)        \n",
    "    def transform(self, datax, datay=None):\n",
    "        return self.ct.transform(datax)\n",
    "    def fit_transform(self, datax, datay=None):\n",
    "        self.fit(datax)\n",
    "        return self.ct.fit_transform(datax)\n",
    "    def set_params(self,**params):\n",
    "        for p in params:\n",
    "            if p in self.options:\n",
    "                self.options[p] = params[p]\n",
    "            else:\n",
    "                s = p.split(\"__\",1)\n",
    "                hyperparameters = {}\n",
    "                hyperparameters[s[1]] = params[p]\n",
    "                self.something[s[0]].set_params(**hyperparameters)              \n",
    "    def get_params(self,deep=True):\n",
    "        return self.options\n",
    "    def __repr__(self):\n",
    "        msg=\"\\n\"\n",
    "        msg += str(self.something['caterogy_pipe'].named_steps['caterogy_imputer_step'])\n",
    "        msg += \"\\n\"\n",
    "        msg += str(self.something['caterogy_pipe'].named_steps['caterogy_encoder_step'])\n",
    "        msg += \"\\n\"\n",
    "        msg += str(self.something['num_pipe'].named_steps['num_imputer_step'])\n",
    "        msg += \"\\n\"\n",
    "        msg += str(self.something['num_pipe'].named_steps['num_scaler_step'])\n",
    "        return msg\n",
    "    \n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data.data)\n",
    "y = data.target\n",
    "param_grid = {\n",
    "    'dataProcess__caterogy_pipe__caterogy_imputer_step__fill_value': ['AAA','BBB'],\n",
    "    'dataProcess__num_pipe__num_imputer_step__strategy': ['median','mean'],\n",
    "    'SVC__kernel': ['linear','poly'],\n",
    "    'SVC__C': [0.01,0.1,1,10,100,1000],\n",
    "}\n",
    "\n",
    "ml_pipe = Pipeline([('dataProcess',dataProcess()), ('SVC',  SVC())])\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "# estimator need provide a score function\n",
    "gsearch = GridSearchCV(estimator=ml_pipe, param_grid=param_grid, cv=kf,iid=False, n_jobs=1)\n",
    "gsearch.fit(X, y)\n",
    "\n",
    "gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('dataProcess',\n",
      "SimpleImputer(copy=True, fill_value='AAA', missing_values=nan,\n",
      "       strategy='constant', verbose=0)\n",
      "OneHotEncoder(categorical_features=None, categories=None,\n",
      "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
      "       n_values=None, sparse=False)\n",
      "SimpleImputer(cop...r', max_iter=-1, probability=False, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "print(gsearch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myKernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
